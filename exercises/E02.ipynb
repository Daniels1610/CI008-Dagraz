{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E02 : Adversarial Search (Minimax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "from classes.Game import Board\n",
    "from IPython.display import display\n",
    "from classes.misc.Color import Color\n",
    "from classes.players.HumanPlayer import HumanPlayer\n",
    "from classes.players.SmartComputerPlayer import SmartComputerPlayer\n",
    "\n",
    "GAME_DIMS = (3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.01:** Apply Backtracking to Binary Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el siguiente grafo, utilizando backtracking determine la ruta  \n",
    "con la cual se alcanza el estado meta representado por el nodo  \n",
    "$X_{G} = M$, considere que el estado de inicio es $X_{I} = A$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.02:** Minimax Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere un juego que tiene cuatro estados finales y los caminos para alcanzar el estado final van desde la raíz hasta las cuatro hojas de un árbol binario perfecto, como se muestra en la figura.\n",
    "\n",
    "<img src=\"../imgs/e2.02_tree.jpeg\" alt=\"Árbol de Juego\" width=200 height=200>\n",
    "  \n",
    "Supongamos que usted es el jugador que maximiza y tiene la primera oportunidad de mover, es decir, esta en la raíz y su oponente en el siguiente nivel.  \n",
    "  \n",
    "- ¿Qué movimiento haría como jugador maximizador considerando que su oponente también juega de manera óptima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**  \n",
    "\n",
    "$max\\;(min (3,5),\\;min(2,9))$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.03:** Implement Minimax Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[3,5,2,9],\n",
    "        [3,5,2,9,12,5,23,23],\n",
    "        [-1,4,2,6,-3,-5,0,7]]\n",
    "\n",
    "def pairwise(iterable):\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def minmax(terminals:np.ndarray) -> np.int32:\n",
    "    levels = int(np.log2(len(terminals)))\n",
    "    if levels == 1: return np.max(terminals)\n",
    "    elif levels % 2 == 0:\n",
    "        return minmax(np.array([np.minimum(a,b) for a,b in pairwise(terminals)]))\n",
    "    else:\n",
    "        return minmax(np.array([np.maximum(a,b) for a,b in pairwise(terminals)]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(len(inputs)):\n",
    "        print(f\"Test Input #{i}\")\n",
    "        print(f\"{minmax(inputs[i])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.04:** Implement `initial_state()` functions for Tic-Tac-Toe Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implementar en Google Colab la función `initial_state()`. La cual  \n",
    "establece $S_{0}$, el **estado inicial**, que especifica la configuración inicial del  \n",
    "juego (en nuestro caso, un tablero vacío de ($3 \\times 3$). La función debe  \n",
    "regresar una lista $3 \\times 3$ con contenido `'None'` en cada elemento.\n",
    "  \n",
    "2) Implementar en Google Colab una función para desplegar la información  \n",
    "del tablero (estado actual) en forma gráfica utilizando: Matplotlib,  \n",
    "Pygame, Tkinter, OpenCV, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board((3,3))\n",
    "print(f\"{Color.BOLD}Board State (Array){Color.END}: \\n{board.state}\")\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move = np.array([0,1])\n",
    "board.make_move(move)\n",
    "board.update_board(move)\n",
    "display(board.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset board\n",
    "board.init_state()\n",
    "display(board.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.05**: Implement `Player(s)` and `Actions(s)` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implementar en Google Colab la función `Player(s)`.  \n",
    "La cual regresa a que jugador `(X o O)` le toca mover  \n",
    "dado el estado $s$.\n",
    "  \n",
    "2) Implementar en Google Colab la función `Actions(s)`.  \n",
    "La cual regresa un conjunto de acciones legales (qué  \n",
    "lugares están libres) dado un estado $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Board(GAME_DIMS)\n",
    "print(f'PLAYER IN TURN: {Color.BOLD}{Color.BLUE if b.player() == \"X\" else Color.RED} {b.player()}{Color.END}')\n",
    "print(f\"ACTIONS:\\n{b.actions()}\")\n",
    "display(b.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X's Move 1\n",
    "b.make_move(np.array([2,2]))\n",
    "b.update_board(np.array([2,2]))\n",
    "print(f'PLAYER IN TURN: {Color.BOLD}{Color.BLUE if b.player() == \"X\" else Color.RED} {b.player()}{Color.END}')\n",
    "print(f\"ACTIONS:\\n{b.actions()}\")\n",
    "display(b.board) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O's Move 1\n",
    "b.make_move(np.array([1,2]))\n",
    "b.update_board(np.array([1,2]))\n",
    "print(f'PLAYER IN TURN: {Color.BOLD}{Color.BLUE if b.player() == \"X\" else Color.RED} {b.player()}{Color.END}')\n",
    "print(f\"ACTIONS:\\n{b.actions()}\")\n",
    "display(b.board) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Reproduce Game with Random Moves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_game():\n",
    "    # Create Board Board\n",
    "    b = Board(GAME_DIMS)\n",
    "    # Game continues while there are None values on the board\n",
    "    while (np.any(b.state == None)):\n",
    "        # Get available actions for player in turn\n",
    "        U = b.actions()\n",
    "        player = b.player()\n",
    "        print(f'PLAYER IN TURN: {Color.BOLD}{Color.BLUE if player == \"X\" else Color.RED} {player}{Color.END}')\n",
    "        print(f'ACTIONS FROM TURN {b.ply}:\\n{U}')\n",
    "        \n",
    "        # Randomly selects one action from action space\n",
    "        z = U[np.random.choice(U.shape[0], size=1, replace=False), :] \n",
    "\n",
    "        # Execute selected move\n",
    "        b.make_move(z)\n",
    "        b.update_board(z.flatten())\n",
    "        winner = b.winner()\n",
    "        print(f\"MOVE PLAYED: {z.flatten()}\")\n",
    "        print(f\"WINNER: {winner} \")\n",
    "        print(f'IS TERMINAL: {b.is_terminal()}')\n",
    "        print(f\"UTILITY: {b.utility()}\")\n",
    "        display(b.board)\n",
    "        if winner: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.06:** Implement `Terminal(s)` and `Winner(s)` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implementar en Google Colab la función `Terminal(s)`.  \n",
    "La cual regresa verdadero (True) cuando el juego  \n",
    "termina (es decir, verificar si alguien ganó o hay empate)\n",
    "\n",
    "2) Implementar en Google Colab la función `Winner(s)`.  \n",
    "La cual regresa el ganado del juego (X o O) o `None` \n",
    "en caso de empate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Board(GAME_DIMS)\n",
    "b.make_move(np.array([1,0])); b.update_board(np.array([1,0]))\n",
    "b.make_move(np.array([0,2])); b.update_board(np.array([0,2]))\n",
    "b.make_move(np.array([1,1])); b.update_board(np.array([1,1]))\n",
    "b.make_move(np.array([0,0])); b.update_board(np.array([0,0]))\n",
    "b.make_move(np.array([2,0])); b.update_board(np.array([2,0]))\n",
    "b.make_move(np.array([0,1])); b.update_board(np.array([0,1]))\n",
    "winner = b.winner()\n",
    "display(b.board)\n",
    "print(f\"WINNER: {winner} \")\n",
    "print(f'IS TERMINAL: {b.is_terminal()}')\n",
    "print(f\"UTILITY: {b.utility()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **E2.07:** Implementar `Result(s,a)` y `Utility(s)` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implementar en Google Colab la función `Result(s,a)`. La  \n",
    "cual codifica el **modelo de transición**, función que regresa  \n",
    "el estado resultante de tomar la acción\n",
    "\n",
    "2) Implementar en Google Colab la función `Utility(s)`. La  \n",
    "cual define el valor numérico final para el jugador cuando  \n",
    "el juego termina en el estado terminal `s`. Devuelve el valor  \n",
    "de utilidad del estado: -1, 0 o 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = Board(GAME_DIMS)\n",
    "bb.make_move(np.array([0,2]))\n",
    "bb.update_board(np.array([0,2]))\n",
    "display(bb.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.utility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.08:** Implement Minimax Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(board, depth):\n",
    "    if board.is_terminal() or depth == 0:\n",
    "        return board.utility(), None\n",
    "\n",
    "    best_value = -math.inf if board.player() == 'X' else math.inf\n",
    "    best_move = None\n",
    "\n",
    "    for move in board.actions():\n",
    "        board.make_move(move)\n",
    "        val, _ = minimax(copy.deepcopy(board), depth - 1)\n",
    "        board.undo_move()\n",
    "\n",
    "        if board.player() == 'X':\n",
    "            if val > best_value:\n",
    "                best_value = val\n",
    "                best_move = move\n",
    "        else:\n",
    "            if val < best_value:\n",
    "                best_value = val\n",
    "                best_move = move\n",
    "\n",
    "    return best_value, best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimax Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Board(GAME_DIMS)\n",
    "b = Board((3,3))\n",
    "b.set_state(np.array([[None,1,0],[0,1,None],[1,None,0]]))\n",
    "print(b.state)\n",
    "print(minimax(copy.deepcopy(b), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.09:** Implement Game Mode (Player can select between X and O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implementar en Google Colab el juego de \n",
    "Tic-Tac-Toe de forma completa empleando \n",
    "las funciones previamente desarrolladas.\n",
    "\n",
    "2) La dinámica del juego es la siguiente:  \n",
    "    a) El usuario selecciona 'X' u 'O'  \n",
    "    b) Siempre inicial el juego 'X' (MAX).  \n",
    "    c) Llevar a cabo el juego entre agente y usuario.  \n",
    "    d) Desplegar el estado de juego a cada paso (movimiento)  \n",
    "    e) Desplegar resultado final (ganador o empate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(game:Board, x_player, o_player):\n",
    "    while (np.any(game.state == None) and not game.is_terminal()):\n",
    "        # Gets Player X/O move\n",
    "        move = x_player.get_move(game) if game.player() == 'X' else o_player.get_move(game)\n",
    "        game.make_move(move)\n",
    "    \n",
    "        print(f\"{game.state}\\n\")\n",
    "        game.update_board(move)\n",
    "        display(game.board)\n",
    "    winner = game.winner()\n",
    "    if winner == 'X': print(f\"PLAYER {x_player.letter} HAS WON!!\")\n",
    "    elif winner == 'O': print(f\"PLAYER {o_player.letter} HAS WON!!\")\n",
    "    else: print(f\"GAME ENDED IN A DRAW!\")\n",
    "    game.init_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to Tic-Tac-Toe Game!!\")\n",
    "human_player = input(\"Select your Player X/O: \")\n",
    "t = Board(GAME_DIMS)\n",
    "x_player = HumanPlayer('X') if human_player == 'X' else SmartComputerPlayer('X')\n",
    "o_player = HumanPlayer('O') if human_player == 'O' else SmartComputerPlayer('O')\n",
    "\n",
    "play(t, x_player, o_player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
